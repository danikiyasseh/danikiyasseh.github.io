<!DOCTYPE HTML>
<!--
	Spectral by Pixelarity
	pixelarity.com @pixelarity
	License: pixelarity.com/license
-->
<html>
	<head>
		<link rel="icon" href="">
		<title>Dani Kiyasseh | Blog - AI4Surgery </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                               tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
                               });
        </script>
        <script type="text/javascript"
  			src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>
		<script>
		  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		  ga('create', 'UA-97381584-1', 'auto');
		  ga('send', 'pageview');

		</script>

		
		

	</head>
  
  
	<body>

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header">
						<h1><a href="../../index.html">Dani Kiyasseh</a></h1>
						<nav id="nav">
							<ul>
								<li class="special">
									<a href="#menu" class="menuToggle"><span>Menu</span></a>
									<div id="menu">
										<ul>
											<li><a href="../../index.html">Home</a></li>
											<li><a href="../../index.html#aboutme">About Me</a></li>
											<li><a href="../../index.html#experience">Experience</a></li>
											<li>&mdash;</li>
											<li><a href="../../publications.html">Publications</a></li>
											<li><a href="../index.html">Blog</a></li>
											<li><a href="../../datasets.html">Datasets</a></li>											
										</ul>
									</div>
								</li>
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<article id="main">
						<section class="wrapper style5">

							<div class="inner">
								<h2>
								<center>
									Quantification of Robotic Surgeries with Vision-Based Deep Learning 
								</center>
								</h2>
								
								<p>
								<center>
									Sunday, May 9th, 2022
								</center>
								</p>
								
								<p>
								<center>
									Dani Kiyasseh
								</center>
								</p>
								
								<p>
								It is estimated that 200 million surgeries are performed annually and worldwide. Around 15% of these surgical procedures are performed with the assistance of a robotic device. 
                Such robotic surgeries have proven to be effective in reducing intra-operative complications (read: what goes wrong during surgery), shortening the post-operative recovery time for patients
                (read: patients get better faster), and improving long-term patient outcomes. 
								</p>
                
                <h4>
                The Surgical Triad
                </h4>
                  <p>
                  During a surgical procedure, robotic or otherwise, a surgeon must often navigate critical anatomical structures, such as nerves and blood vessels, avoid harming healthy tissue, and actively avoid 
                  potential complications, all the while tending to the main task at hand. This complexity is juxtaposed with the simplicity of the overarching goal of surgery: 
                  to improve post-operative surgical and patient outcomes. Recent studies have in fact shown that intra-operative surgical activity (<i>what</i> and <i>how</i> a surgical procedure is performed) can have a 
                  direct impact on long-term patient outcomes. Knowledge of this relationship can guide the provision of feedback to surgeons in order to modulate their future behaviour. We refer to the three components 
                  of intra-operative surgical activity, post-operative patient outcomes, and surgeon feedback as the <i>surgical triad</i>. 
                  </p>
                
                  % include image of surgical triad
                	<center>
									<img src="./images/clustering_and_retrieval.png" style="width: 40vw;" /> 									
								  </center>
                
                <h4>
                The Core Elements of Surgery
                </h4>
                  <p>
                  To better understand the relationship between intra-operative surgical activity and post-operative patient outcomes, we believe that the core elements of surgery must be first quantified in an objective,
                  reliable, and scalable manner. This involves, for example, identifying <i>what</i> and <i>how</i> activity is performed during surgery. 
                  </p>
                  
                  <p>
                  The core elements of surgery can be understood by considering a particular robotic surgery (figure below), known as a robot-assisted radical prostatectomy (RARP), in which the prostate gland is removed from a patient's body
                  due to the presence of cancerous tissue. This procedure consists of multiple <i>steps</i> over time, such as dissection (read: cutting tissue) and suturing (read: joining tissue), which reflect the <i>wha</i> of surgery. Each of these 
                  steps can be executed through a sequence of manoeuvres, or gestures, and at a different skill level depicting low- or high-quality activity. Together, these elements reflect the <i>how</i> of surgery.  
                  </p>
                  
                  % include image of RARP over time
                	<center>
									<img src="./images/elements_of_surgery.gif" /> 									
								  </center>
                
                <h4
                Quantifying the Core Elements of Surgery via Roboformer
                </h4>
                  <p>
                  In our research, we design a deep learning framework, entitled Roboformer, that quantifies the core elements of surgery in an objective, reliable, and scalable manner.
                  This framework is <i>unified</i> in that the same network architecture can be used, without any modifications, to achieve multiple machine learning tasks (i.e., quantify multiple elements of surgery).
                  It is also <i>vision-based</i> in that is depends exclusively on videos recorded during surgery, which are straightforward to acquire from surgical robotic devices, to perform these machine learning tasks. 
                  </p>


<!-- 								<h4>
								Acknowledgements
								</h4>
								<p>  
								We would like to thank Antong Chen for reviewing a preliminary version of the associated manuscript. We would also like to thank <a id='overwhite' href="https://www.youtube.com/watch?v=uQk9VTLvzLA"><u>Nagat Al-Saghira</u></a> and <a id='overwhite' href="https://www.youtube.com/watch?v=C6SPcxQdK8M"><u>Mohammed Abdel Wahab</u></a> for lending us their voice. 
								</p> -->
								
							    </br>
							
							</div>
						</section>
					</article>
    
		
			</div>

		<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/jquery.scrollex.min.js"></script>
			<script src="../../assets/js/jquery.scrolly.min.js"></script>
			<script src="../../assets/js/skel.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="../../assets/js/main.js"></script>
				
				
  	</body>
	
</html>
